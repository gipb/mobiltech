{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import os\n",
    "\n",
    "import easydict\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from opts import opts\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.17</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({\"K\": 100,\n",
    "\"aggr_weight\": 0.0,\n",
    "\"agnostic_ex\": False,\n",
    "\"arch\": \"dla_34\",\n",
    "\"aug_ddd\": 0.5,\n",
    "\"aug_rot\": 0,\n",
    "\"batch_size\": 16,\n",
    "\"cat_spec_wh\": False,\n",
    "\"center_thresh\": 0.1,\n",
    "\"chunk_sizes\": [15],\n",
    "\"data_dir\": \"/mnt/nas/data\",\n",
    "\"dataset\": \"mobiltech\",\n",
    "\"debug\": 0,\n",
    "\"debug_dir\": \"/mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla/debug\",\n",
    "\"debugger_theme\": \"white\",\n",
    "\"demo\": \"/root/practice/CenterNet_objdet2D/images/mobiltech_test\",\n",
    "\"dense_hp\": False,\n",
    "\"dense_wh\": False,\n",
    "\"dep_weight\": 1,\n",
    "\"dim_weight\": 1,\n",
    "\"down_ratio\": 4,\n",
    "\"eval_oracle_dep\": False,\n",
    "\"eval_oracle_hm\": False,\n",
    "\"eval_oracle_hmhp\": False,\n",
    "\"eval_oracle_hp_offset\": False,\n",
    "\"eval_oracle_kps\": False,\n",
    "\"eval_oracle_offset\": False,\n",
    "\"eval_oracle_wh\": False,\n",
    "\"exp_dir\": \"/mnt/nas/centernet/exp/ctdet\",\n",
    "\"exp_id\": \"mobiltech_dla\",\n",
    "\"fix_res\": True,\n",
    "\"flip\": 1.5,\n",
    "\"flip_test\": True,\n",
    "\"gpus\": [0],\n",
    "\"gpus_str\": 0,\n",
    "\"head_conv\": 256,\n",
    "\"heads\": {'hm': 66, 'wh': 2, 'reg': 2},\n",
    "\"hide_data_time\": False,\n",
    "\"hm_hp\": True,\n",
    "\"hm_hp_weight\": 1,\n",
    "\"hm_weight\": 1,\n",
    "\"hp_weight\": 1,\n",
    "\"input_h\": 512,\n",
    "\"input_res\": 512,\n",
    "\"input_w\": 512,\n",
    "\"keep_res\": False,\n",
    "\"kitti_split\": \"3dop\",\n",
    "\"load_model\": \"/mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla/model_230.pth\",\n",
    "\"lr\": 0.0005,\n",
    "\"lr_step\": [180, 210],\n",
    "\"master_batch_size\": 15,\n",
    "\"mean\": [[[0.40789655, 0.44719303, 0.47026116]]],\n",
    "\"metric\": \"loss\",\n",
    "\"mse_loss\": False,\n",
    "\"nms\": False,\n",
    "\"no_color_aug\": False,\n",
    "\"norm_wh\": False,\n",
    "\"not_cuda_benchmark\": False,\n",
    "\"not_hm_hp\": False,\n",
    "\"not_prefetch_test\": False,\n",
    "\"not_rand_crop\": False,\n",
    "\"not_reg_bbox\": False,\n",
    "\"not_reg_hp_offset\": False,\n",
    "\"not_reg_offset\": False,\n",
    "\"num_classes\": 66,\n",
    "\"num_epochs\": 230,\n",
    "\"num_iters\": -1,\n",
    "\"num_stacks\": 1,\n",
    "\"num_workers\": 4,\n",
    "\"off_weight\": 1,\n",
    "\"output_h\": 128,\n",
    "\"output_res\": 128,\n",
    "\"output_w\": 128,\n",
    "\"pad\": 31,\n",
    "\"peak_thresh\": 0.2,\n",
    "\"print_iter\": 0,\n",
    "\"rect_mask\": False,\n",
    "\"reg_bbox\": True,\n",
    "\"reg_hp_offset\": True,\n",
    "\"reg_loss\": \"l1\",\n",
    "\"reg_offset\": True,\n",
    "\"resume\": False,\n",
    "\"root_dir\": \"/mnt/nas\",\n",
    "\"rot_weight\": 1,\n",
    "\"rotate\": 0,\n",
    "\"save_all\": True,\n",
    "\"save_dir\": \"/mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla\",\n",
    "\"scale\": 0.4,\n",
    "\"scores_thresh\": 0.1,\n",
    "\"seed\": 317,\n",
    "\"shift\": 0.1,\n",
    "\"std\": [[[0.2886383, 0.27408165, 0.27809834]]],\n",
    "\"task\": \"ctdet\",\n",
    "\"test\": False,\n",
    "\"test_scales\": [1.0],\n",
    "\"trainval\": False,\n",
    "\"val_intervals\": 5,\n",
    "\"vis_thresh\": 0.3,\n",
    "\"wh_weight\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads {'hm': 66, 'wh': 2, 'reg': 2}\n",
      "{'K': 100, 'aggr_weight': 0.0, 'agnostic_ex': False, 'arch': 'dla_34', 'aug_ddd': 0.5, 'aug_rot': 0, 'batch_size': 16, 'cat_spec_wh': False, 'center_thresh': 0.1, 'chunk_sizes': [15], 'data_dir': '/mnt/nas/data', 'dataset': 'mobiltech', 'debug': 0, 'debug_dir': '/mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla/debug', 'debugger_theme': 'white', 'demo': '/root/practice/CenterNet_objdet2D/images/mobiltech_test', 'dense_hp': False, 'dense_wh': False, 'dep_weight': 1, 'dim_weight': 1, 'down_ratio': 4, 'eval_oracle_dep': False, 'eval_oracle_hm': False, 'eval_oracle_hmhp': False, 'eval_oracle_hp_offset': False, 'eval_oracle_kps': False, 'eval_oracle_offset': False, 'eval_oracle_wh': False, 'exp_dir': '/mnt/nas/centernet/exp/ctdet', 'exp_id': 'mobiltech_dla', 'fix_res': True, 'flip': 1.5, 'flip_test': True, 'gpus': [0], 'gpus_str': 0, 'head_conv': 256, 'heads': {'hm': 66, 'wh': 2, 'reg': 2}, 'hide_data_time': False, 'hm_hp': True, 'hm_hp_weight': 1, 'hm_weight': 1, 'hp_weight': 1, 'input_h': 512, 'input_res': 512, 'input_w': 512, 'keep_res': False, 'kitti_split': '3dop', 'load_model': '/mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla/model_230.pth', 'lr': 0.0005, 'lr_step': [180, 210], 'master_batch_size': 15, 'mean': array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), 'metric': 'loss', 'mse_loss': False, 'nms': False, 'no_color_aug': False, 'norm_wh': False, 'not_cuda_benchmark': False, 'not_hm_hp': False, 'not_prefetch_test': False, 'not_rand_crop': False, 'not_reg_bbox': False, 'not_reg_hp_offset': False, 'not_reg_offset': False, 'num_classes': 66, 'num_epochs': 230, 'num_iters': -1, 'num_stacks': 1, 'num_workers': 4, 'off_weight': 1, 'output_h': 128, 'output_res': 128, 'output_w': 128, 'pad': 31, 'peak_thresh': 0.2, 'print_iter': 0, 'rect_mask': False, 'reg_bbox': True, 'reg_hp_offset': True, 'reg_loss': 'l1', 'reg_offset': True, 'resume': False, 'root_dir': '/mnt/nas', 'rot_weight': 1, 'rotate': 0, 'save_all': True, 'save_dir': '/mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla', 'scale': 0.4, 'scores_thresh': 0.1, 'seed': 317, 'shift': 0.1, 'std': array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), 'task': 'ctdet', 'test': False, 'test_scales': [1.0], 'trainval': False, 'val_intervals': 5, 'vis_thresh': 0.3, 'wh_weight': 0.1}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(opt.seed)\n",
    "torch.backends.cudnn.benchmark = not opt.not_cuda_benchmark and not opt.test\n",
    "Dataset = get_dataset(opt.dataset, opt.task)\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model(opt.arch, opt.heads, opt.head_conv).cuda()\n",
    "#torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /mnt/nas/centernet/exp/ctdet/mobiltech/mobiltech_dla/model_230.pth, epoch 230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DLASeg(\n",
       "  (base): DLA(\n",
       "    (base_layer): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level0): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level2): Tree(\n",
       "      (tree1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (tree2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (root): Root(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level3): Tree(\n",
       "      (tree1): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tree2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level4): Tree(\n",
       "      (tree1): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tree2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level5): Tree(\n",
       "      (tree1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (tree2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (root): Root(\n",
       "        (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (dla_up): DLAUp(\n",
       "    (ida_0): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (ida_1): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (proj_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (node_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (ida_2): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (proj_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (proj_3): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_3): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ida_up): IDAUp(\n",
       "    (proj_1): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "    (node_1): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (proj_2): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)\n",
       "    (node_2): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (hm): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (wh): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (reg): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n",
    "model= load_model(model, opt.load_model).cuda()\n",
    "dummy_input = Variable(torch.randn(16,3,512,512)).cuda()\n",
    "model.train(False)\n",
    "#traced_model = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(16, 3, 512, 512)\n",
      "      %1 : Float(16, 3, 7, 7)\n",
      "      %2 : Float(16)\n",
      "      %3 : Float(16)\n",
      "      %4 : Float(16)\n",
      "      %5 : Float(16)\n",
      "      %6 : Long()\n",
      "      %7 : Float(16, 16, 3, 3)\n",
      "      %8 : Float(16)\n",
      "      %9 : Float(16)\n",
      "      %10 : Float(16)\n",
      "      %11 : Float(16)\n",
      "      %12 : Long()\n",
      "      %13 : Float(32, 16, 3, 3)\n",
      "      %14 : Float(32)\n",
      "      %15 : Float(32)\n",
      "      %16 : Float(32)\n",
      "      %17 : Float(32)\n",
      "      %18 : Long()\n",
      "      %19 : Float(64, 32, 3, 3)\n",
      "      %20 : Float(64)\n",
      "      %21 : Float(64)\n",
      "      %22 : Float(64)\n",
      "      %23 : Float(64)\n",
      "      %24 : Long()\n",
      "      %25 : Float(64, 64, 3, 3)\n",
      "      %26 : Float(64)\n",
      "      %27 : Float(64)\n",
      "      %28 : Float(64)\n",
      "      %29 : Float(64)\n",
      "      %30 : Long()\n",
      "      %31 : Float(64, 64, 3, 3)\n",
      "      %32 : Float(64)\n",
      "      %33 : Float(64)\n",
      "      %34 : Float(64)\n",
      "      %35 : Float(64)\n",
      "      %36 : Long()\n",
      "      %37 : Float(64, 64, 3, 3)\n",
      "      %38 : Float(64)\n",
      "      %39 : Float(64)\n",
      "      %40 : Float(64)\n",
      "      %41 : Float(64)\n",
      "      %42 : Long()\n",
      "      %43 : Float(64, 128, 1, 1)\n",
      "      %44 : Float(64)\n",
      "      %45 : Float(64)\n",
      "      %46 : Float(64)\n",
      "      %47 : Float(64)\n",
      "      %48 : Long()\n",
      "      %49 : Float(64, 32, 1, 1)\n",
      "      %50 : Float(64)\n",
      "      %51 : Float(64)\n",
      "      %52 : Float(64)\n",
      "      %53 : Float(64)\n",
      "      %54 : Long()\n",
      "      %55 : Float(128, 64, 3, 3)\n",
      "      %56 : Float(128)\n",
      "      %57 : Float(128)\n",
      "      %58 : Float(128)\n",
      "      %59 : Float(128)\n",
      "      %60 : Long()\n",
      "      %61 : Float(128, 128, 3, 3)\n",
      "      %62 : Float(128)\n",
      "      %63 : Float(128)\n",
      "      %64 : Float(128)\n",
      "      %65 : Float(128)\n",
      "      %66 : Long()\n",
      "      %67 : Float(128, 128, 3, 3)\n",
      "      %68 : Float(128)\n",
      "      %69 : Float(128)\n",
      "      %70 : Float(128)\n",
      "      %71 : Float(128)\n",
      "      %72 : Long()\n",
      "      %73 : Float(128, 128, 3, 3)\n",
      "      %74 : Float(128)\n",
      "      %75 : Float(128)\n",
      "      %76 : Float(128)\n",
      "      %77 : Float(128)\n",
      "      %78 : Long()\n",
      "      %79 : Float(128, 256, 1, 1)\n",
      "      %80 : Float(128)\n",
      "      %81 : Float(128)\n",
      "      %82 : Float(128)\n",
      "      %83 : Float(128)\n",
      "      %84 : Long()\n",
      "      %85 : Float(128, 64, 1, 1)\n",
      "      %86 : Float(128)\n",
      "      %87 : Float(128)\n",
      "      %88 : Float(128)\n",
      "      %89 : Float(128)\n",
      "      %90 : Long()\n",
      "      %91 : Float(128, 128, 3, 3)\n",
      "      %92 : Float(128)\n",
      "      %93 : Float(128)\n",
      "      %94 : Float(128)\n",
      "      %95 : Float(128)\n",
      "      %96 : Long()\n",
      "      %97 : Float(128, 128, 3, 3)\n",
      "      %98 : Float(128)\n",
      "      %99 : Float(128)\n",
      "      %100 : Float(128)\n",
      "      %101 : Float(128)\n",
      "      %102 : Long()\n",
      "      %103 : Float(128, 128, 3, 3)\n",
      "      %104 : Float(128)\n",
      "      %105 : Float(128)\n",
      "      %106 : Float(128)\n",
      "      %107 : Float(128)\n",
      "      %108 : Long()\n",
      "      %109 : Float(128, 128, 3, 3)\n",
      "      %110 : Float(128)\n",
      "      %111 : Float(128)\n",
      "      %112 : Float(128)\n",
      "      %113 : Float(128)\n",
      "      %114 : Long()\n",
      "      %115 : Float(128, 448, 1, 1)\n",
      "      %116 : Float(128)\n",
      "      %117 : Float(128)\n",
      "      %118 : Float(128)\n",
      "      %119 : Float(128)\n",
      "      %120 : Long()\n",
      "      %121 : Float(128, 64, 1, 1)\n",
      "      %122 : Float(128)\n",
      "      %123 : Float(128)\n",
      "      %124 : Float(128)\n",
      "      %125 : Float(128)\n",
      "      %126 : Long()\n",
      "      %127 : Float(256, 128, 3, 3)\n",
      "      %128 : Float(256)\n",
      "      %129 : Float(256)\n",
      "      %130 : Float(256)\n",
      "      %131 : Float(256)\n",
      "      %132 : Long()\n",
      "      %133 : Float(256, 256, 3, 3)\n",
      "      %134 : Float(256)\n",
      "      %135 : Float(256)\n",
      "      %136 : Float(256)\n",
      "      %137 : Float(256)\n",
      "      %138 : Long()\n",
      "      %139 : Float(256, 256, 3, 3)\n",
      "      %140 : Float(256)\n",
      "      %141 : Float(256)\n",
      "      %142 : Float(256)\n",
      "      %143 : Float(256)\n",
      "      %144 : Long()\n",
      "      %145 : Float(256, 256, 3, 3)\n",
      "      %146 : Float(256)\n",
      "      %147 : Float(256)\n",
      "      %148 : Float(256)\n",
      "      %149 : Float(256)\n",
      "      %150 : Long()\n",
      "      %151 : Float(256, 512, 1, 1)\n",
      "      %152 : Float(256)\n",
      "      %153 : Float(256)\n",
      "      %154 : Float(256)\n",
      "      %155 : Float(256)\n",
      "      %156 : Long()\n",
      "      %157 : Float(256, 128, 1, 1)\n",
      "      %158 : Float(256)\n",
      "      %159 : Float(256)\n",
      "      %160 : Float(256)\n",
      "      %161 : Float(256)\n",
      "      %162 : Long()\n",
      "      %163 : Float(256, 256, 3, 3)\n",
      "      %164 : Float(256)\n",
      "      %165 : Float(256)\n",
      "      %166 : Float(256)\n",
      "      %167 : Float(256)\n",
      "      %168 : Long()\n",
      "      %169 : Float(256, 256, 3, 3)\n",
      "      %170 : Float(256)\n",
      "      %171 : Float(256)\n",
      "      %172 : Float(256)\n",
      "      %173 : Float(256)\n",
      "      %174 : Long()\n",
      "      %175 : Float(256, 256, 3, 3)\n",
      "      %176 : Float(256)\n",
      "      %177 : Float(256)\n",
      "      %178 : Float(256)\n",
      "      %179 : Float(256)\n",
      "      %180 : Long()\n",
      "      %181 : Float(256, 256, 3, 3)\n",
      "      %182 : Float(256)\n",
      "      %183 : Float(256)\n",
      "      %184 : Float(256)\n",
      "      %185 : Float(256)\n",
      "      %186 : Long()\n",
      "      %187 : Float(256, 896, 1, 1)\n",
      "      %188 : Float(256)\n",
      "      %189 : Float(256)\n",
      "      %190 : Float(256)\n",
      "      %191 : Float(256)\n",
      "      %192 : Long()\n",
      "      %193 : Float(256, 128, 1, 1)\n",
      "      %194 : Float(256)\n",
      "      %195 : Float(256)\n",
      "      %196 : Float(256)\n",
      "      %197 : Float(256)\n",
      "      %198 : Long()\n",
      "      %199 : Float(512, 256, 3, 3)\n",
      "      %200 : Float(512)\n",
      "      %201 : Float(512)\n",
      "      %202 : Float(512)\n",
      "      %203 : Float(512)\n",
      "      %204 : Long()\n",
      "      %205 : Float(512, 512, 3, 3)\n",
      "      %206 : Float(512)\n",
      "      %207 : Float(512)\n",
      "      %208 : Float(512)\n",
      "      %209 : Float(512)\n",
      "      %210 : Long()\n",
      "      %211 : Float(512, 512, 3, 3)\n",
      "      %212 : Float(512)\n",
      "      %213 : Float(512)\n",
      "      %214 : Float(512)\n",
      "      %215 : Float(512)\n",
      "      %216 : Long()\n",
      "      %217 : Float(512, 512, 3, 3)\n",
      "      %218 : Float(512)\n",
      "      %219 : Float(512)\n",
      "      %220 : Float(512)\n",
      "      %221 : Float(512)\n",
      "      %222 : Long()\n",
      "      %223 : Float(512, 1280, 1, 1)\n",
      "      %224 : Float(512)\n",
      "      %225 : Float(512)\n",
      "      %226 : Float(512)\n",
      "      %227 : Float(512)\n",
      "      %228 : Long()\n",
      "      %229 : Float(512, 256, 1, 1)\n",
      "      %230 : Float(512)\n",
      "      %231 : Float(512)\n",
      "      %232 : Float(512)\n",
      "      %233 : Float(512)\n",
      "      %234 : Long()\n",
      "      %235 : Float(1000, 512, 1, 1)\n",
      "      %236 : Float(1000)\n",
      "      %237 : Float(256)\n",
      "      %238 : Float(256)\n",
      "      %239 : Float(256)\n",
      "      %240 : Float(256)\n",
      "      %241 : Long()\n",
      "      %242 : Float(256, 512, 3, 3)\n",
      "      %243 : Float(256)\n",
      "      %244 : Float(256, 1, 4, 4)\n",
      "      %245 : Float(256)\n",
      "      %246 : Float(256)\n",
      "      %247 : Float(256)\n",
      "      %248 : Float(256)\n",
      "      %249 : Long()\n",
      "      %250 : Float(256, 256, 3, 3)\n",
      "      %251 : Float(256)\n",
      "      %252 : Float(128)\n",
      "      %253 : Float(128)\n",
      "      %254 : Float(128)\n",
      "      %255 : Float(128)\n",
      "      %256 : Long()\n",
      "      %257 : Float(128, 256, 3, 3)\n",
      "      %258 : Float(128)\n",
      "      %259 : Float(128, 1, 4, 4)\n",
      "      %260 : Float(128)\n",
      "      %261 : Float(128)\n",
      "      %262 : Float(128)\n",
      "      %263 : Float(128)\n",
      "      %264 : Long()\n",
      "      %265 : Float(128, 128, 3, 3)\n",
      "      %266 : Float(128)\n",
      "      %267 : Float(128)\n",
      "      %268 : Float(128)\n",
      "      %269 : Float(128)\n",
      "      %270 : Float(128)\n",
      "      %271 : Long()\n",
      "      %272 : Float(128, 256, 3, 3)\n",
      "      %273 : Float(128)\n",
      "      %274 : Float(128, 1, 4, 4)\n",
      "      %275 : Float(128)\n",
      "      %276 : Float(128)\n",
      "      %277 : Float(128)\n",
      "      %278 : Float(128)\n",
      "      %279 : Long()\n",
      "      %280 : Float(128, 128, 3, 3)\n",
      "      %281 : Float(128)\n",
      "      %282 : Float(64)\n",
      "      %283 : Float(64)\n",
      "      %284 : Float(64)\n",
      "      %285 : Float(64)\n",
      "      %286 : Long()\n",
      "      %287 : Float(64, 128, 3, 3)\n",
      "      %288 : Float(64)\n",
      "      %289 : Float(64, 1, 4, 4)\n",
      "      %290 : Float(64)\n",
      "      %291 : Float(64)\n",
      "      %292 : Float(64)\n",
      "      %293 : Float(64)\n",
      "      %294 : Long()\n",
      "      %295 : Float(64, 64, 3, 3)\n",
      "      %296 : Float(64)\n",
      "      %297 : Float(64)\n",
      "      %298 : Float(64)\n",
      "      %299 : Float(64)\n",
      "      %300 : Float(64)\n",
      "      %301 : Long()\n",
      "      %302 : Float(64, 128, 3, 3)\n",
      "      %303 : Float(64)\n",
      "      %304 : Float(64, 1, 4, 4)\n",
      "      %305 : Float(64)\n",
      "      %306 : Float(64)\n",
      "      %307 : Float(64)\n",
      "      %308 : Float(64)\n",
      "      %309 : Long()\n",
      "      %310 : Float(64, 64, 3, 3)\n",
      "      %311 : Float(64)\n",
      "      %312 : Float(64)\n",
      "      %313 : Float(64)\n",
      "      %314 : Float(64)\n",
      "      %315 : Float(64)\n",
      "      %316 : Long()\n",
      "      %317 : Float(64, 128, 3, 3)\n",
      "      %318 : Float(64)\n",
      "      %319 : Float(64, 1, 4, 4)\n",
      "      %320 : Float(64)\n",
      "      %321 : Float(64)\n",
      "      %322 : Float(64)\n",
      "      %323 : Float(64)\n",
      "      %324 : Long()\n",
      "      %325 : Float(64, 64, 3, 3)\n",
      "      %326 : Float(64)\n",
      "      %327 : Float(64)\n",
      "      %328 : Float(64)\n",
      "      %329 : Float(64)\n",
      "      %330 : Float(64)\n",
      "      %331 : Long()\n",
      "      %332 : Float(64, 128, 3, 3)\n",
      "      %333 : Float(64)\n",
      "      %334 : Float(64, 1, 4, 4)\n",
      "      %335 : Float(64)\n",
      "      %336 : Float(64)\n",
      "      %337 : Float(64)\n",
      "      %338 : Float(64)\n",
      "      %339 : Long()\n",
      "      %340 : Float(64, 64, 3, 3)\n",
      "      %341 : Float(64)\n",
      "      %342 : Float(64)\n",
      "      %343 : Float(64)\n",
      "      %344 : Float(64)\n",
      "      %345 : Float(64)\n",
      "      %346 : Long()\n",
      "      %347 : Float(64, 256, 3, 3)\n",
      "      %348 : Float(64)\n",
      "      %349 : Float(64, 1, 8, 8)\n",
      "      %350 : Float(64)\n",
      "      %351 : Float(64)\n",
      "      %352 : Float(64)\n",
      "      %353 : Float(64)\n",
      "      %354 : Long()\n",
      "      %355 : Float(64, 64, 3, 3)\n",
      "      %356 : Float(64)\n",
      "      %357 : Float(256, 64, 3, 3)\n",
      "      %358 : Float(256)\n",
      "      %359 : Float(66, 256, 1, 1)\n",
      "      %360 : Float(66)\n",
      "      %361 : Float(256, 64, 3, 3)\n",
      "      %362 : Float(256)\n",
      "      %363 : Float(2, 256, 1, 1)\n",
      "      %364 : Float(2)\n",
      "      %365 : Float(256, 64, 3, 3)\n",
      "      %366 : Float(256)\n",
      "      %367 : Float(2, 256, 1, 1)\n",
      "      %368 : Float(2)) {\n",
      "  %369 : Float(16, 16, 512, 512) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[1, 1]](%0, %1), scope: DLASeg/DLA[base]/Sequential[base_layer]/Conv2d[0]\n",
      "  %370 : Float(16, 16, 512, 512) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%369, %2, %3, %4, %5), scope: DLASeg/DLA[base]/Sequential[base_layer]/BatchNorm2d[1]\n",
      "  %371 : Float(16, 16, 512, 512) = onnx::Relu(%370), scope: DLASeg/DLA[base]/Sequential[base_layer]/ReLU[2]\n",
      "  %372 : Float(16, 16, 512, 512) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%371, %7), scope: DLASeg/DLA[base]/Sequential[level0]/Conv2d[0]\n",
      "  %373 : Float(16, 16, 512, 512) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%372, %8, %9, %10, %11), scope: DLASeg/DLA[base]/Sequential[level0]/BatchNorm2d[1]\n",
      "  %374 : Float(16, 16, 512, 512) = onnx::Relu(%373), scope: DLASeg/DLA[base]/Sequential[level0]/ReLU[2]\n",
      "  %375 : Float(16, 32, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%374, %13), scope: DLASeg/DLA[base]/Sequential[level1]/Conv2d[0]\n",
      "  %376 : Float(16, 32, 256, 256) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%375, %14, %15, %16, %17), scope: DLASeg/DLA[base]/Sequential[level1]/BatchNorm2d[1]\n",
      "  %377 : Float(16, 32, 256, 256) = onnx::Relu(%376), scope: DLASeg/DLA[base]/Sequential[level1]/ReLU[2]\n",
      "  %378 : Float(16, 32, 128, 128) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%377), scope: DLASeg/DLA[base]/Tree[level2]/MaxPool2d[downsample]\n",
      "  %379 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%378, %49), scope: DLASeg/DLA[base]/Tree[level2]/Sequential[project]/Conv2d[0]\n",
      "  %380 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%379, %50, %51, %52, %53), scope: DLASeg/DLA[base]/Tree[level2]/Sequential[project]/BatchNorm2d[1]\n",
      "  %381 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%377, %19), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]/Conv2d[conv1]\n",
      "  %382 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%381, %20, %21, %22, %23), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]/BatchNorm2d[bn1]\n",
      "  %383 : Float(16, 64, 128, 128) = onnx::Relu(%382), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %384 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%383, %25), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]/Conv2d[conv2]\n",
      "  %385 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%384, %26, %27, %28, %29), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]/BatchNorm2d[bn2]\n",
      "  %386 : Float(16, 64, 128, 128) = onnx::Add(%385, %380), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]\n",
      "  %387 : Float(16, 64, 128, 128) = onnx::Relu(%386), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %388 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%387, %31), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]/Conv2d[conv1]\n",
      "  %389 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%388, %32, %33, %34, %35), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]/BatchNorm2d[bn1]\n",
      "  %390 : Float(16, 64, 128, 128) = onnx::Relu(%389), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %391 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%390, %37), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]/Conv2d[conv2]\n",
      "  %392 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%391, %38, %39, %40, %41), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]/BatchNorm2d[bn2]\n",
      "  %393 : Float(16, 64, 128, 128) = onnx::Add(%392, %387), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]\n",
      "  %394 : Float(16, 64, 128, 128) = onnx::Relu(%393), scope: DLASeg/DLA[base]/Tree[level2]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %395 : Float(16, 128, 128, 128) = onnx::Concat[axis=1](%394, %387), scope: DLASeg/DLA[base]/Tree[level2]/Root[root]\n",
      "  %396 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%395, %43), scope: DLASeg/DLA[base]/Tree[level2]/Root[root]/Conv2d[conv]\n",
      "  %397 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%396, %44, %45, %46, %47), scope: DLASeg/DLA[base]/Tree[level2]/Root[root]/BatchNorm2d[bn]\n",
      "  %398 : Float(16, 64, 128, 128) = onnx::Relu(%397), scope: DLASeg/DLA[base]/Tree[level2]/Root[root]/ReLU[relu]\n",
      "  %399 : Float(16, 64, 64, 64) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%398), scope: DLASeg/DLA[base]/Tree[level3]/MaxPool2d[downsample]\n",
      "  %400 : Float(16, 64, 64, 64) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%398), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/MaxPool2d[downsample]\n",
      "  %401 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%400, %85), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/Sequential[project]/Conv2d[0]\n",
      "  %402 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%401, %86, %87, %88, %89), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/Sequential[project]/BatchNorm2d[1]\n",
      "  %403 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%398, %55), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]/Conv2d[conv1]\n",
      "  %404 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%403, %56, %57, %58, %59), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]/BatchNorm2d[bn1]\n",
      "  %405 : Float(16, 128, 64, 64) = onnx::Relu(%404), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %406 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%405, %61), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]/Conv2d[conv2]\n",
      "  %407 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%406, %62, %63, %64, %65), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]/BatchNorm2d[bn2]\n",
      "  %408 : Float(16, 128, 64, 64) = onnx::Add(%407, %402), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]\n",
      "  %409 : Float(16, 128, 64, 64) = onnx::Relu(%408), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %410 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%409, %67), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]/Conv2d[conv1]\n",
      "  %411 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%410, %68, %69, %70, %71), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]/BatchNorm2d[bn1]\n",
      "  %412 : Float(16, 128, 64, 64) = onnx::Relu(%411), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %413 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%412, %73), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]/Conv2d[conv2]\n",
      "  %414 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%413, %74, %75, %76, %77), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]/BatchNorm2d[bn2]\n",
      "  %415 : Float(16, 128, 64, 64) = onnx::Add(%414, %409), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]\n",
      "  %416 : Float(16, 128, 64, 64) = onnx::Relu(%415), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %417 : Float(16, 256, 64, 64) = onnx::Concat[axis=1](%416, %409), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/Root[root]\n",
      "  %418 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%417, %79), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/Root[root]/Conv2d[conv]\n",
      "  %419 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%418, %80, %81, %82, %83), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/Root[root]/BatchNorm2d[bn]\n",
      "  %420 : Float(16, 128, 64, 64) = onnx::Relu(%419), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree1]/Root[root]/ReLU[relu]\n",
      "  %421 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%420, %91), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]/Conv2d[conv1]\n",
      "  %422 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%421, %92, %93, %94, %95), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]/BatchNorm2d[bn1]\n",
      "  %423 : Float(16, 128, 64, 64) = onnx::Relu(%422), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %424 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%423, %97), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]/Conv2d[conv2]\n",
      "  %425 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%424, %98, %99, %100, %101), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]/BatchNorm2d[bn2]\n",
      "  %426 : Float(16, 128, 64, 64) = onnx::Add(%425, %420), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]\n",
      "  %427 : Float(16, 128, 64, 64) = onnx::Relu(%426), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %428 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%427, %103), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]/Conv2d[conv1]\n",
      "  %429 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%428, %104, %105, %106, %107), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]/BatchNorm2d[bn1]\n",
      "  %430 : Float(16, 128, 64, 64) = onnx::Relu(%429), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %431 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%430, %109), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]/Conv2d[conv2]\n",
      "  %432 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%431, %110, %111, %112, %113), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]/BatchNorm2d[bn2]\n",
      "  %433 : Float(16, 128, 64, 64) = onnx::Add(%432, %427), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]\n",
      "  %434 : Float(16, 128, 64, 64) = onnx::Relu(%433), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %435 : Float(16, 448, 64, 64) = onnx::Concat[axis=1](%434, %427, %399, %420), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/Root[root]\n",
      "  %436 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%435, %115), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/Root[root]/Conv2d[conv]\n",
      "  %437 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%436, %116, %117, %118, %119), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/Root[root]/BatchNorm2d[bn]\n",
      "  %438 : Float(16, 128, 64, 64) = onnx::Relu(%437), scope: DLASeg/DLA[base]/Tree[level3]/Tree[tree2]/Root[root]/ReLU[relu]\n",
      "  %439 : Float(16, 128, 32, 32) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%438), scope: DLASeg/DLA[base]/Tree[level4]/MaxPool2d[downsample]\n",
      "  %440 : Float(16, 128, 32, 32) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%438), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/MaxPool2d[downsample]\n",
      "  %441 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%440, %157), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/Sequential[project]/Conv2d[0]\n",
      "  %442 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%441, %158, %159, %160, %161), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/Sequential[project]/BatchNorm2d[1]\n",
      "  %443 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%438, %127), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]/Conv2d[conv1]\n",
      "  %444 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%443, %128, %129, %130, %131), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]/BatchNorm2d[bn1]\n",
      "  %445 : Float(16, 256, 32, 32) = onnx::Relu(%444), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %446 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%445, %133), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]/Conv2d[conv2]\n",
      "  %447 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%446, %134, %135, %136, %137), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]/BatchNorm2d[bn2]\n",
      "  %448 : Float(16, 256, 32, 32) = onnx::Add(%447, %442), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]\n",
      "  %449 : Float(16, 256, 32, 32) = onnx::Relu(%448), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %450 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%449, %139), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]/Conv2d[conv1]\n",
      "  %451 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%450, %140, %141, %142, %143), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]/BatchNorm2d[bn1]\n",
      "  %452 : Float(16, 256, 32, 32) = onnx::Relu(%451), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %453 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%452, %145), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]/Conv2d[conv2]\n",
      "  %454 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%453, %146, %147, %148, %149), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]/BatchNorm2d[bn2]\n",
      "  %455 : Float(16, 256, 32, 32) = onnx::Add(%454, %449), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]\n",
      "  %456 : Float(16, 256, 32, 32) = onnx::Relu(%455), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %457 : Float(16, 512, 32, 32) = onnx::Concat[axis=1](%456, %449), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/Root[root]\n",
      "  %458 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%457, %151), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/Root[root]/Conv2d[conv]\n",
      "  %459 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%458, %152, %153, %154, %155), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/Root[root]/BatchNorm2d[bn]\n",
      "  %460 : Float(16, 256, 32, 32) = onnx::Relu(%459), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree1]/Root[root]/ReLU[relu]\n",
      "  %461 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%460, %163), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]/Conv2d[conv1]\n",
      "  %462 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%461, %164, %165, %166, %167), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]/BatchNorm2d[bn1]\n",
      "  %463 : Float(16, 256, 32, 32) = onnx::Relu(%462), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %464 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%463, %169), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]/Conv2d[conv2]\n",
      "  %465 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%464, %170, %171, %172, %173), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]/BatchNorm2d[bn2]\n",
      "  %466 : Float(16, 256, 32, 32) = onnx::Add(%465, %460), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]\n",
      "  %467 : Float(16, 256, 32, 32) = onnx::Relu(%466), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %468 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%467, %175), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]/Conv2d[conv1]\n",
      "  %469 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%468, %176, %177, %178, %179), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]/BatchNorm2d[bn1]\n",
      "  %470 : Float(16, 256, 32, 32) = onnx::Relu(%469), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %471 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%470, %181), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]/Conv2d[conv2]\n",
      "  %472 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%471, %182, %183, %184, %185), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]/BatchNorm2d[bn2]\n",
      "  %473 : Float(16, 256, 32, 32) = onnx::Add(%472, %467), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]\n",
      "  %474 : Float(16, 256, 32, 32) = onnx::Relu(%473), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %475 : Float(16, 896, 32, 32) = onnx::Concat[axis=1](%474, %467, %439, %460), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/Root[root]\n",
      "  %476 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%475, %187), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/Root[root]/Conv2d[conv]\n",
      "  %477 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%476, %188, %189, %190, %191), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/Root[root]/BatchNorm2d[bn]\n",
      "  %478 : Float(16, 256, 32, 32) = onnx::Relu(%477), scope: DLASeg/DLA[base]/Tree[level4]/Tree[tree2]/Root[root]/ReLU[relu]\n",
      "  %479 : Float(16, 256, 16, 16) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%478), scope: DLASeg/DLA[base]/Tree[level5]/MaxPool2d[downsample]\n",
      "  %480 : Float(16, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%479, %229), scope: DLASeg/DLA[base]/Tree[level5]/Sequential[project]/Conv2d[0]\n",
      "  %481 : Float(16, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%480, %230, %231, %232, %233), scope: DLASeg/DLA[base]/Tree[level5]/Sequential[project]/BatchNorm2d[1]\n",
      "  %482 : Float(16, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%478, %199), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]/Conv2d[conv1]\n",
      "  %483 : Float(16, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%482, %200, %201, %202, %203), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]/BatchNorm2d[bn1]\n",
      "  %484 : Float(16, 512, 16, 16) = onnx::Relu(%483), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %485 : Float(16, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%484, %205), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]/Conv2d[conv2]\n",
      "  %486 : Float(16, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%485, %206, %207, %208, %209), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]/BatchNorm2d[bn2]\n",
      "  %487 : Float(16, 512, 16, 16) = onnx::Add(%486, %481), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]\n",
      "  %488 : Float(16, 512, 16, 16) = onnx::Relu(%487), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree1]/ReLU[relu]\n",
      "  %489 : Float(16, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%488, %211), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]/Conv2d[conv1]\n",
      "  %490 : Float(16, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%489, %212, %213, %214, %215), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]/BatchNorm2d[bn1]\n",
      "  %491 : Float(16, 512, 16, 16) = onnx::Relu(%490), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %492 : Float(16, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%491, %217), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]/Conv2d[conv2]\n",
      "  %493 : Float(16, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%492, %218, %219, %220, %221), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]/BatchNorm2d[bn2]\n",
      "  %494 : Float(16, 512, 16, 16) = onnx::Add(%493, %488), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]\n",
      "  %495 : Float(16, 512, 16, 16) = onnx::Relu(%494), scope: DLASeg/DLA[base]/Tree[level5]/BasicBlock[tree2]/ReLU[relu]\n",
      "  %496 : Float(16, 1280, 16, 16) = onnx::Concat[axis=1](%495, %488, %479), scope: DLASeg/DLA[base]/Tree[level5]/Root[root]\n",
      "  %497 : Float(16, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%496, %223), scope: DLASeg/DLA[base]/Tree[level5]/Root[root]/Conv2d[conv]\n",
      "  %498 : Float(16, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%497, %224, %225, %226, %227), scope: DLASeg/DLA[base]/Tree[level5]/Root[root]/BatchNorm2d[bn]\n",
      "  %499 : Float(16, 512, 16, 16) = onnx::Relu(%498), scope: DLASeg/DLA[base]/Tree[level5]/Root[root]/ReLU[relu]\n",
      "  %500 : Float(16, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%499, %242, %243), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/DeformConv[proj_1]/Conv2d[conv]\n",
      "  %501 : Float(16, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%500, %237, %238, %239, %240), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/DeformConv[proj_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %502 : Float(16, 256, 16, 16) = onnx::Relu(%501), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/DeformConv[proj_1]/Sequential[actf]/ReLU[1]\n",
      "  %503 : Float(16, 256, 32, 32) = onnx::ConvTranspose[dilations=[1, 1], group=256, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%502, %244), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/ConvTranspose2d[up_1]\n",
      "  %504 : Float(16, 256, 32, 32) = onnx::Add(%503, %478), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]\n",
      "  %505 : Float(16, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%504, %250, %251), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/DeformConv[node_1]/Conv2d[conv]\n",
      "  %506 : Float(16, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%505, %245, %246, %247, %248), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/DeformConv[node_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %507 : Float(16, 256, 32, 32) = onnx::Relu(%506), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_0]/DeformConv[node_1]/Sequential[actf]/ReLU[1]\n",
      "  %508 : Float(16, 128, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%478, %257, %258), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[proj_1]/Conv2d[conv]\n",
      "  %509 : Float(16, 128, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%508, %252, %253, %254, %255), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[proj_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %510 : Float(16, 128, 32, 32) = onnx::Relu(%509), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[proj_1]/Sequential[actf]/ReLU[1]\n",
      "  %511 : Float(16, 128, 64, 64) = onnx::ConvTranspose[dilations=[1, 1], group=128, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%510, %259), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/ConvTranspose2d[up_1]\n",
      "  %512 : Float(16, 128, 64, 64) = onnx::Add(%511, %438), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]\n",
      "  %513 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%512, %265, %266), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[node_1]/Conv2d[conv]\n",
      "  %514 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%513, %260, %261, %262, %263), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[node_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %515 : Float(16, 128, 64, 64) = onnx::Relu(%514), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[node_1]/Sequential[actf]/ReLU[1]\n",
      "  %516 : Float(16, 128, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%507, %272, %273), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[proj_2]/Conv2d[conv]\n",
      "  %517 : Float(16, 128, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%516, %267, %268, %269, %270), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[proj_2]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %518 : Float(16, 128, 32, 32) = onnx::Relu(%517), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[proj_2]/Sequential[actf]/ReLU[1]\n",
      "  %519 : Float(16, 128, 64, 64) = onnx::ConvTranspose[dilations=[1, 1], group=128, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%518, %274), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/ConvTranspose2d[up_2]\n",
      "  %520 : Float(16, 128, 64, 64) = onnx::Add(%519, %515), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]\n",
      "  %521 : Float(16, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%520, %280, %281), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[node_2]/Conv2d[conv]\n",
      "  %522 : Float(16, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%521, %275, %276, %277, %278), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[node_2]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %523 : Float(16, 128, 64, 64) = onnx::Relu(%522), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_1]/DeformConv[node_2]/Sequential[actf]/ReLU[1]\n",
      "  %524 : Float(16, 64, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%438, %287, %288), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_1]/Conv2d[conv]\n",
      "  %525 : Float(16, 64, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%524, %282, %283, %284, %285), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %526 : Float(16, 64, 64, 64) = onnx::Relu(%525), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_1]/Sequential[actf]/ReLU[1]\n",
      "  %527 : Float(16, 64, 128, 128) = onnx::ConvTranspose[dilations=[1, 1], group=64, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%526, %289), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/ConvTranspose2d[up_1]\n",
      "  %528 : Float(16, 64, 128, 128) = onnx::Add(%527, %398), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]\n",
      "  %529 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%528, %295, %296), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_1]/Conv2d[conv]\n",
      "  %530 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%529, %290, %291, %292, %293), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %531 : Float(16, 64, 128, 128) = onnx::Relu(%530), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_1]/Sequential[actf]/ReLU[1]\n",
      "  %532 : Float(16, 64, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%515, %302, %303), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_2]/Conv2d[conv]\n",
      "  %533 : Float(16, 64, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%532, %297, %298, %299, %300), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_2]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %534 : Float(16, 64, 64, 64) = onnx::Relu(%533), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_2]/Sequential[actf]/ReLU[1]\n",
      "  %535 : Float(16, 64, 128, 128) = onnx::ConvTranspose[dilations=[1, 1], group=64, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%534, %304), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/ConvTranspose2d[up_2]\n",
      "  %536 : Float(16, 64, 128, 128) = onnx::Add(%535, %531), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]\n",
      "  %537 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%536, %310, %311), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_2]/Conv2d[conv]\n",
      "  %538 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%537, %305, %306, %307, %308), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_2]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %539 : Float(16, 64, 128, 128) = onnx::Relu(%538), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_2]/Sequential[actf]/ReLU[1]\n",
      "  %540 : Float(16, 64, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%523, %317, %318), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_3]/Conv2d[conv]\n",
      "  %541 : Float(16, 64, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%540, %312, %313, %314, %315), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_3]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %542 : Float(16, 64, 64, 64) = onnx::Relu(%541), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[proj_3]/Sequential[actf]/ReLU[1]\n",
      "  %543 : Float(16, 64, 128, 128) = onnx::ConvTranspose[dilations=[1, 1], group=64, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%542, %319), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/ConvTranspose2d[up_3]\n",
      "  %544 : Float(16, 64, 128, 128) = onnx::Add(%543, %539), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]\n",
      "  %545 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%544, %325, %326), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_3]/Conv2d[conv]\n",
      "  %546 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%545, %320, %321, %322, %323), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_3]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %547 : Float(16, 64, 128, 128) = onnx::Relu(%546), scope: DLASeg/DLAUp[dla_up]/IDAUp[ida_2]/DeformConv[node_3]/Sequential[actf]/ReLU[1]\n",
      "  %548 : Float(16, 64, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%523, %332, %333), scope: DLASeg/IDAUp[ida_up]/DeformConv[proj_1]/Conv2d[conv]\n",
      "  %549 : Float(16, 64, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%548, %327, %328, %329, %330), scope: DLASeg/IDAUp[ida_up]/DeformConv[proj_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %550 : Float(16, 64, 64, 64) = onnx::Relu(%549), scope: DLASeg/IDAUp[ida_up]/DeformConv[proj_1]/Sequential[actf]/ReLU[1]\n",
      "  %551 : Float(16, 64, 128, 128) = onnx::ConvTranspose[dilations=[1, 1], group=64, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%550, %334), scope: DLASeg/IDAUp[ida_up]/ConvTranspose2d[up_1]\n",
      "  %552 : Float(16, 64, 128, 128) = onnx::Add(%551, %547), scope: DLASeg/IDAUp[ida_up]\n",
      "  %553 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%552, %340, %341), scope: DLASeg/IDAUp[ida_up]/DeformConv[node_1]/Conv2d[conv]\n",
      "  %554 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%553, %335, %336, %337, %338), scope: DLASeg/IDAUp[ida_up]/DeformConv[node_1]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %555 : Float(16, 64, 128, 128) = onnx::Relu(%554), scope: DLASeg/IDAUp[ida_up]/DeformConv[node_1]/Sequential[actf]/ReLU[1]\n",
      "  %556 : Float(16, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%507, %347, %348), scope: DLASeg/IDAUp[ida_up]/DeformConv[proj_2]/Conv2d[conv]\n",
      "  %557 : Float(16, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%556, %342, %343, %344, %345), scope: DLASeg/IDAUp[ida_up]/DeformConv[proj_2]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %558 : Float(16, 64, 32, 32) = onnx::Relu(%557), scope: DLASeg/IDAUp[ida_up]/DeformConv[proj_2]/Sequential[actf]/ReLU[1]\n",
      "  %559 : Float(16, 64, 128, 128) = onnx::ConvTranspose[dilations=[1, 1], group=64, kernel_shape=[8, 8], pads=[2, 2, 2, 2], strides=[4, 4]](%558, %349), scope: DLASeg/IDAUp[ida_up]/ConvTranspose2d[up_2]\n",
      "  %560 : Float(16, 64, 128, 128) = onnx::Add(%559, %555), scope: DLASeg/IDAUp[ida_up]\n",
      "  %561 : Float(16, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%560, %355, %356), scope: DLASeg/IDAUp[ida_up]/DeformConv[node_2]/Conv2d[conv]\n",
      "  %562 : Float(16, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%561, %350, %351, %352, %353), scope: DLASeg/IDAUp[ida_up]/DeformConv[node_2]/Sequential[actf]/BatchNorm2d[0]\n",
      "  %563 : Float(16, 64, 128, 128) = onnx::Relu(%562), scope: DLASeg/IDAUp[ida_up]/DeformConv[node_2]/Sequential[actf]/ReLU[1]\n",
      "  %564 : Float(16, 256, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%563, %357, %358), scope: DLASeg/Sequential[hm]/Conv2d[0]\n",
      "  %565 : Float(16, 256, 128, 128) = onnx::Relu(%564), scope: DLASeg/Sequential[hm]/ReLU[1]\n",
      "  %566 : Float(16, 66, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%565, %359, %360), scope: DLASeg/Sequential[hm]/Conv2d[2]\n",
      "  %567 : Float(16, 256, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%563, %361, %362), scope: DLASeg/Sequential[wh]/Conv2d[0]\n",
      "  %568 : Float(16, 256, 128, 128) = onnx::Relu(%567), scope: DLASeg/Sequential[wh]/ReLU[1]\n",
      "  %569 : Float(16, 2, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%568, %363, %364), scope: DLASeg/Sequential[wh]/Conv2d[2]\n",
      "  %570 : Float(16, 256, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%563, %365, %366), scope: DLASeg/Sequential[reg]/Conv2d[0]\n",
      "  %571 : Float(16, 256, 128, 128) = onnx::Relu(%570), scope: DLASeg/Sequential[reg]/ReLU[1]\n",
      "  %572 : Float(16, 2, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%571, %367, %368), scope: DLASeg/Sequential[reg]/Conv2d[2]\n",
      "  return (%566, %569, %572);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, dummy_input, \"centernet.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ONNX",
   "language": "python",
   "name": "onnx_practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
